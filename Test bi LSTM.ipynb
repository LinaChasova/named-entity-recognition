{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T14:26:24.344604Z",
     "start_time": "2020-04-29T14:26:24.339030Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:45:45.421532Z",
     "start_time": "2020-04-29T13:45:45.417437Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:40:00.041319Z",
     "start_time": "2020-04-29T13:40:00.036760Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:51:12.729755Z",
     "start_time": "2020-04-29T13:51:12.725704Z"
    }
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "EMBED_DIM = 300\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "PAD_WORD = '`'\n",
    "PAD_TAG = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:40:18.360325Z",
     "start_time": "2020-04-29T13:40:18.355216Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_train_split(df, ratio=.2):\n",
    "    max_doc = df.iloc[-1].doc\n",
    "    # :ratio: - percentage of data left to testing\n",
    "    split_doc = max_doc * (1 - ratio)\n",
    "\n",
    "    df_train = df[df.doc <= split_doc]\n",
    "    df_test = df[df.doc > split_doc]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:40:20.125467Z",
     "start_time": "2020-04-29T13:40:20.119411Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data(df):\n",
    "    sentences = []\n",
    "\n",
    "    doc_ids = list(set(df.doc))\n",
    "    for doc_id in doc_ids:\n",
    "        sent_ids = list(set(df[df.doc == doc_id].sentence))\n",
    "        df_docs = df[df.doc == doc_id]\n",
    "        for sent_id in sent_ids:\n",
    "            df_sents = df_docs[df_docs.sentence == sent_id]\n",
    "\n",
    "            words = [word for word in df_sents.word]\n",
    "            tags = [tag for tag in df_sents.type]\n",
    "\n",
    "            sentences.append((words, tags))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:41:10.196348Z",
     "start_time": "2020-04-29T13:41:10.186844Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(sentences, word_to_ix, tag_to_ix):\n",
    "    '''\n",
    "        sentences - [[token, ...], [token, ...], ...]\n",
    "        converts sentences to word indices\n",
    "    '''\n",
    "    all_word_indices = []\n",
    "    all_target_indices = []\n",
    "    for sent in sentences:\n",
    "        word_indices, target_indices = get_indices_train(\n",
    "            sent, word_to_ix, tag_to_ix)\n",
    "        all_word_indices.append(word_indices)\n",
    "        all_target_indices.append(target_indices)\n",
    "    return all_word_indices, all_target_indices\n",
    "\n",
    "\n",
    "def get_indices_train(sentence, word_to_ix, tag_to_ix):\n",
    "    '''\n",
    "        retrieves indices of sentence from helpping dictionaries,\n",
    "        maximum length of word in sentence\n",
    "    '''\n",
    "    word_indices = []\n",
    "    target_indices = []\n",
    "    for token in range(len(sentence[0])):\n",
    "        # read word index from dictionary\n",
    "        # if word is not in the dictionary treat as unknown word\n",
    "        tok = sentence[0][token] if sentence[0][\n",
    "            token] in word_to_ix else PAD_WORD\n",
    "        tag = sentence[1][token] if sentence[1][token] in tag_to_ix else PAD_TAG\n",
    "        try:\n",
    "            word_indices.append(word_to_ix[tok])\n",
    "        except:\n",
    "            print(sentence[0])\n",
    "        try:\n",
    "            target_indices.append(tag_to_ix[tag])\n",
    "        except:\n",
    "            print(sentence[1])\n",
    "            print(tag, sentence[1][token])\n",
    "\n",
    "    return torch.tensor(word_indices,\n",
    "                        dtype=torch.long), torch.tensor(target_indices,\n",
    "                                                        dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:41:13.574489Z",
     "start_time": "2020-04-29T13:41:13.559622Z"
    }
   },
   "outputs": [],
   "source": [
    "class Event_tagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 word_to_ix,\n",
    "                 tag_to_ix,\n",
    "                 ix_to_tag,\n",
    "                 weights_matrix,\n",
    "                 batch_size,\n",
    "                 word_embed_dim=300,\n",
    "                 lstm_num_layers=2,\n",
    "                 bidirectional=True,\n",
    "                 dropout=.5):\n",
    "        '''\n",
    "            initialize models\n",
    "            batch_size      - size of batches for traininig\n",
    "            word_embed_dim  - dimension of word embeddings\n",
    "            lstm_num_layers - number of LSTM layers\n",
    "            dropout         - rate for dropout layer\n",
    "        '''\n",
    "        super(Event_tagger, self).__init__()\n",
    "\n",
    "        # dictionaries\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.ix_to_tag = ix_to_tag\n",
    "\n",
    "        # parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.word_embed_dim = word_embed_dim\n",
    "        self.lstm_hidden_dim = self.word_embed_dim\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.word_embeds, num_embeds = create_embed_layer(weights_matrix, True)\n",
    "        self.lstm_hidden_embeds = self.init_hidden_embeddings(self.batch_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.word_embed_dim,\n",
    "                            self.lstm_hidden_dim,\n",
    "                            dropout=self.dropout,\n",
    "                            num_layers=self.lstm_num_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(self.lstm_hidden_dim * self.num_directions,\n",
    "                               len(self.tag_to_ix))\n",
    "\n",
    "    def init_hidden_embeddings(self, batch_size):\n",
    "        '''\n",
    "            initialize hidden embeddings as zeros\n",
    "        '''\n",
    "        return (torch.zeros(self.lstm_num_layers * self.num_directions,\n",
    "                            batch_size, self.lstm_hidden_dim),\n",
    "                torch.zeros(self.lstm_num_layers * self.num_directions,\n",
    "                            batch_size, self.lstm_hidden_dim))\n",
    "        \n",
    "    def forward(self, words_batch):\n",
    "        '''\n",
    "            words_batch - contains indices of words in current batch with shape\n",
    "                        (batch_size, num_words_in_sentence)\n",
    "\n",
    "            creates word level word embeddings from words_batch\n",
    "\n",
    "            runs Bi-directional LSTM over input word representation to get\n",
    "            final word representation which is fed to linear layer and softmax\n",
    "            activation function to generate probability distribution for event\n",
    "            tag set\n",
    "        '''\n",
    "        # create word-level word embeddings\n",
    "        word_embed_word_level = words_batch.view(-1)\n",
    "        word_embed_word_level = self.word_embeds(word_embed_word_level)\n",
    "        batch_sent_embed = word_embed_word_level.view(words_batch.shape[0], -1,\n",
    "                                                 word_embed_word_level.shape[-1])\n",
    "\n",
    "        # create final word representation from LSTM\n",
    "        lstm_out, self.lstm_hidden_embeds = self.lstm(batch_sent_embed,\n",
    "                                                      self.lstm_hidden_embeds)\n",
    "\n",
    "        # get probabilities for event tag\n",
    "        tag_space = self.dense(lstm_out)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=2)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:51:02.315326Z",
     "start_time": "2020-04-29T13:51:02.305150Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_sentences(model, df):\n",
    "    batch_size = 1\n",
    "\n",
    "    model.lstm_hidden_embeds = model.init_hidden_embeddings(batch_size)\n",
    "    model.lstm.flatten_parameters()\n",
    "\n",
    "    word_to_ix = model.word_to_ix\n",
    "    ix_to_tag = model.ix_to_tag\n",
    "    tag_to_ix = model.tag_to_ix\n",
    "    tag_to_ix[-1] = len(tag_to_ix)\n",
    "    # print(tag_to_ix['-1'])\n",
    "\n",
    "    # load test dataset\n",
    "    data = create_data(df)\n",
    "    print(data[0])\n",
    "\n",
    "    predicted_tags = []\n",
    "    y_true = []\n",
    "\n",
    "    word_indices, target_indices = sentences_to_indices(\n",
    "        data, word_to_ix, tag_to_ix)\n",
    "    # run test dataset through model\n",
    "    for i in range(len(word_indices)):\n",
    "        tag_scores = model(torch.stack([word_indices[i]]))\n",
    "        out_probs = torch.squeeze(tag_scores)\n",
    "        tmp = []\n",
    "        for j, pset in enumerate(out_probs):\n",
    "            if j >= len(word_indices[i]):\n",
    "                break\n",
    "            _, predicted_ix = torch.max(pset, 0)\n",
    "            predicted_tags.append(predicted_ix.item())\n",
    "            tmp.append(predicted_ix.item())\n",
    "        y_true.extend(target_indices[i])\n",
    "    return predicted_tags, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T14:36:03.881920Z",
     "start_time": "2020-04-29T14:36:03.868130Z"
    }
   },
   "outputs": [],
   "source": [
    "def conf_matrix(y_true, y_pred, tag_to_ix):\n",
    "    y_true = [int(y) for y in y_true]\n",
    "    labels = set(tag_to_ix.values())\n",
    "    neg_class = tag_to_ix['O']\n",
    "\n",
    "    tp, fp, fn = {}, {}, {}\n",
    "    for label in labels:\n",
    "        tp[label], fp[label], fn[label] = 0, 0, 0\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true == neg_class:\n",
    "            continue\n",
    "        tp[true] += 1 if true == pred else 0  # true positive\n",
    "        fn[true] += 1 if true != pred else 0  # false negative\n",
    "        fp[pred] += 1 if true != pred else 0  # false positive\n",
    "    return tp, fp, fn\n",
    "\n",
    "\n",
    "def precision_score(tp, fp, tag_to_ix):\n",
    "    labels = set(tag_to_ix.values())\n",
    "    neg_class = tag_to_ix['O']\n",
    "\n",
    "    tp_sum, tp_fp_sum = 0, 0\n",
    "    for label in labels:\n",
    "        if label == neg_class:\n",
    "            continue\n",
    "        tp_sum += tp[label]\n",
    "        tp_fp_sum += tp[label] + fp[label]\n",
    "\n",
    "    precision = tp_sum / tp_fp_sum\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall_score(tp, fn, tag_to_ix):\n",
    "    labels = set(tag_to_ix.values())\n",
    "    neg_class = tag_to_ix['O']\n",
    "\n",
    "    tp_sum, tp_fn_sum = 0, 0\n",
    "    for label in labels:\n",
    "        if label == neg_class:\n",
    "            continue\n",
    "        tp_sum += tp[label]\n",
    "        tp_fn_sum += tp[label] + fn[label]\n",
    "\n",
    "    recall = tp_sum / tp_fn_sum\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:50:48.120291Z",
     "start_time": "2020-04-29T13:50:47.709807Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '../models/biLSTM-model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "df = pd.read_csv('../output.csv')\n",
    "df_train, df_test = test_train_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T13:52:03.291871Z",
     "start_time": "2020-04-29T13:51:16.942020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Автобус', 'столкнулся', 'с', '\"', 'Газелью', '\"', 'под', 'Уфой', ':', '10', 'пострадавших', 'УФА', ',', '2', 'июля', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-T-GPE-Location', 'O', 'B-T-Person', 'I-T-Person', 'B-T-GPE-Location', 'O', 'B-T-Time', 'I-T-Time', 'O'])\n"
     ]
    }
   ],
   "source": [
    "predicted_tags, y_true = test_sentences(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T14:36:09.265796Z",
     "start_time": "2020-04-29T14:36:09.193588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score 0.808\n",
      "Recall score 0.663\n",
      "F1 score 0.728\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn = conf_matrix(y_true, predicted_tags, model.tag_to_ix)\n",
    "\n",
    "precision = precision_score(tp, fp, model.tag_to_ix)\n",
    "recall = recall_score(tp, fn, model.tag_to_ix)\n",
    "f1 = f1_score(precision, recall)\n",
    "print('Precision score {:.3f}'.format(precision))\n",
    "print('Recall score {:.3f}'.format(recall))\n",
    "print('F1 score {:.3f}'.format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
